## Deployment Plan for a New Task Management System

This plan outlines the steps to transition from the current file-based task management system to a more robust, scalable, and feature-rich system, addressing the flaws identified in Task 18.

### 1. System Architecture Overview:

*   **Centralized Database:** A single source of truth for all tasks across all agents, replacing disparate CSV files.
*   **Internal API Layer:** A set of well-defined endpoints that agents can interact with to create, read, update, and delete tasks. This layer abstracts the underlying database implementation from the agents, promoting modularity and ease of change.
*   **Automated Task Processor (Optional, for future phases):** A dedicated component responsible for automated task ID generation, prioritization, and dependency resolution, reducing manual overhead.

### 2. Recommended Technologies:

*   **Database:**
    *   **Initial Deployment:** SQLite. It's lightweight, embedded, and suitable for a file-based system, making it easy to get started without complex server setup.
    *   **Future Scalability:** PostgreSQL. If the number of tasks or agents grows significantly, or if concurrent access becomes a bottleneck, PostgreSQL offers robustness, scalability, and advanced features.
*   **API Framework:** Python with Flask or FastAPI. Both are lightweight, easy to learn, and integrate seamlessly with existing Python-based agents, allowing for rapid development of the internal API.
*   **Task Data Format:** JSON. This format is flexible, human-readable, and easily parsed/generated by agents, making data exchange efficient.

### 3. Detailed Implementation Steps:

#### Phase 1: Database and Core API Development

*   **Step 1.1: Database Schema Definition:**
    *   Define a `tasks` table with the following columns to capture comprehensive task information:
        *   `task_id` (Primary Key, auto-incrementing for automated ID generation)
        *   `creation_date` (Timestamp)
        *   `creator` (Text)
        *   `category` (Text)
        *   `priority` (Integer)
        *   `description` (Text)
        *   `planned_end_date` (Date, Nullable)
        *   `ai_notes` (Text, Nullable)
        *   `status` (Text, e.g., 'Proposal', 'Approved', 'In Progress', 'Blocked', 'Under Review', 'Done' - expanded statuses)
        *   `real_end_date` (Date, Nullable)
        *   `dependencies` (JSON array of `task_id`s, Nullable - for dependency management)
        *   `assigned_agent` (Text, Nullable)
        *   `last_modified` (Timestamp, auto-updated - for auditing and version control)
*   **Step 1.2: Database Initialization Script:**
    *   Create a Python script to initialize the chosen database (e.g., SQLite) and create the `tasks` table based on the defined schema.
*   **Step 1.3: Internal API Development (Flask/FastAPI):**
    *   Develop RESTful API endpoints for core task operations:
        *   `POST /tasks`: Create a new task. This endpoint will handle automated `task_id` generation, `creation_date`, and `last_modified` timestamps.
        *   `GET /tasks`: Retrieve all tasks. Implement optional query parameters for filtering by `status`, `assigned_agent`, `category`, etc.
        *   `GET /tasks/{task_id}`: Retrieve a specific task by its ID.
        *   `PUT /tasks/{task_id}`: Update an existing task. Ensure only allowed fields can be modified and `last_modified` is automatically updated.
        *   `DELETE /tasks/{task_id}`: Delete a task. Implement appropriate access control to prevent unauthorized deletions.
    *   Implement basic authentication/authorization for API access (e.g., API keys for each agent to identify themselves).

#### Phase 2: Agent Integration and Data Migration

*   **Step 2.1: Update Agent Task Management Logic:**
    *   Modify each agent's operational mandate and underlying Python scripts to interact with the new API endpoints instead of directly reading from and writing to CSV files.
    *   Replace all existing CSV parsing and writing logic with corresponding API calls.
*   **Step 2.2: Data Migration:**
    *   Develop a one-time migration script to transfer all existing tasks from the individual `_tasks.csv` files into the new centralized database. This script should map existing CSV fields to the new database schema.
*   **Step 2.3: Automated Task ID Generation Integration:**
    *   Ensure all agents, when creating new tasks, call the `POST /tasks` API endpoint, which will handle the automated ID generation.
*   **Step 2.4: Expanded Statuses Integration:**
    *   Update agent logic to utilize the new, expanded set of task statuses, providing more granular control and visibility.

#### Phase 3: Advanced Features and Refinements

*   **Step 3.1: Automated Prioritization Logic:**
    *   Implement a background process or a dedicated API endpoint that can periodically re-prioritize tasks based on predefined rules (e.g., priority level, due date, dependencies, strategic alignment).
*   **Step 3.2: Task Dependency Enforcement:**
    *   Implement logic within the API to check and enforce task dependencies. For example, prevent a task from being marked "In Progress" if its prerequisite tasks are not yet "Done."
*   **Step 3.3: Delegated Approval Mechanism:**
    *   Introduce a mechanism for delegated approval, potentially allowing agents to approve certain types of tasks for other agents, or implementing a peer-review system. This would require additional API endpoints and logic within the API layer.
*   **Step 3.4: Version Control for Task Changes (Auditing):**
    *   Implement a simple auditing mechanism within the database (e.g., a separate `task_history` table) to log all changes made to tasks, including who made the change and when. This provides a form of version control and audit trail.

### 4. Key Considerations:

*   **Scalability:** Plan for future growth. While SQLite is suitable for initial deployment, be prepared to migrate to a more robust database like PostgreSQL if the system scales significantly.
*   **Security:** Implement robust authentication and authorization for the API. Ensure sensitive task data is handled securely, especially if the system is exposed beyond the local environment.
*   **Maintainability:** Keep the API and database schema well-documented. Use clear, modular code with proper comments. Implement automated tests for the API.
*   **Error Handling:** Implement comprehensive error handling and logging in both the API and agent-side logic to quickly identify and resolve issues.
*   **Monitoring:** Set up basic monitoring for the API to track its availability, performance, and any errors.
*   **Backward Compatibility:** During the transition, ensure that agents can still function (perhaps in a limited capacity) if the new system is not fully deployed or if there are issues.

This detailed deployment plan provides a clear roadmap for enhancing the task management capabilities of the AI Company, leading to improved efficiency, visibility, and collaboration among agents.